\documentclass[11pt]{article} 
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{geometry}
\geometry{a4paper, margin=1in}
\usepackage{graphicx}
\usepackage[hidelinks]{hyperref}
\usepackage{amsthm}
\usepackage{tikz}
\usepackage{subcaption}
\usetikzlibrary{positioning}
\usepackage{pgfplots} 
\usepackage[ruled,vlined]{algorithm2e} 
\usepackage{dsfont}
\usepackage{graphicx}
\usepackage{mathdesign}
\usepackage{float}
\usepackage{todonotes} 
\usepackage{empheq}
\usepackage{array}
\usepackage[ruled,vlined]{algorithm2e} 
\usepackage[many]{tcolorbox}    	% for COLORED BOXES (tikz and xcolor included)



\newtcolorbox{boxA}{
    fontupper = \bf,
    boxrule = 1.5pt,
    colframe = black % frame color
}


\setlength{\parindent}{0pt}
\numberwithin{equation}{section}


\newcommand\mycommfont[1]{\footnotesize\ttfamily\textcolor{blue}{#1}}
\newcommand\defeq{\stackrel{\mathclap{\normalfont\mbox{def}}}{=}}
\SetCommentSty{mycommfont}

\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}



\newtheoremstyle{boldStyle}%                % Name
  {}%                                     % Space above
  {}%                                     % Space below
  {\itshape}%                                     % Body font
  {}%                                     % Indent amount
  {\bfseries}%                            % Theorem head font
  {}%                                    % Punctuation after theorem head
  {\newline}                              % Space after theorem head, new line
  {\thmname{#1}\thmnumber{ #2}\thmnote{ (#3)}}%                                     % Theorem head spec (can be left empty, meaning `normal')


\theoremstyle{boldStyle}
\newtheorem{example}{Example}[section]

\newtheorem*{claim*}{Claim}
\newtheorem*{lemma*}{Lemma}
\newtheorem*{corollary*}{Corollary}
\newtheorem*{remark*}{Remark}
\newtheorem*{example*}{Example}
\newtheorem*{examples*}{Examples}
\newtheorem*{definition*}{Definition}



\definecolor{blueColor}{rgb}{0, 0.611, 0.98} 
\newtheoremstyle{boldBlueStyle}%                % Name
  {}%                                          % Space above
  {}%                                          % Space below
  {\itshape}%                                  % Body font
  {}%                                          % Indent amount
  {\color{blueColor}\bfseries}%          % Theorem head font in red
  {}%                                          % Punctuation after theorem head
  {\newline}%                                  % Space after theorem head, new line
  {\thmname{#1}\thmnumber{ #2}\thmnote{ (#3)}} % Theorem head spec (can be left empty, meaning `normal')

\theoremstyle{boldBlueStyle}
\newtheorem{lemma}{Lemma}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{claim}{claim}[section]


\definecolor{purpleColor}{rgb}{0.59, 0.223, 0.6} 
\newtheoremstyle{boldPurpleStyle}%                % Name
  {}%                                          % Space above
  {}%                                          % Space below
  {\itshape}%                                  % Body font
  {}%                                          % Indent amount
  {\color{purpleColor}\bfseries}%          % Theorem head font in red
  {}%                                          % Punctuation after theorem head
  {\newline}%                                  % Space after theorem head, new line
  {\thmname{#1}\thmnumber{ #2}\thmnote{ (#3)}} % Theorem head spec (can be left empty, meaning `normal')

\theoremstyle{boldPurpleStyle}
\newtheorem{theorem}{Theorem}[section]


\definecolor{redColor}{rgb}{1, 0.219, 0.219} 
\newtheoremstyle{boldRedStyle}%                % Name
  {}%                                          % Space above
  {}%                                          % Space below
  {\itshape}%                                  % Body font
  {}%                                          % Indent amount
  {\color{redColor}\bfseries}%          % Theorem head font in red
  {}%                                          % Punctuation after theorem head
  {\newline}%                                  % Space after theorem head, new line
  {\thmname{#1}\thmnumber{ #2}\thmnote{ (#3)}} % Theorem head spec (can be left empty, meaning `normal')

\theoremstyle{boldRedStyle}
\newtheorem{definition}{Definition}[section]




\title{
    \huge Probabilistic Methods in Artifical Intelligence\\
    \vspace{10pt}
}

\author{Hadar Tal}

\date{Hebrew University of Jerusalem, Israel\\
    \vspace{10pt}
    \today}



\begin{document}
\maketitle

\section{Probability Review}

\begin{definition}[Probability Space]
    A probability space is a triple $(\Omega, \mathcal{F}, P)$ where:
    \begin{enumerate}
        \item $\Omega$ is the sample space
        \item $\mathcal{F}$ is a $\sigma$-algebra of subsets of $\Omega$
        \item $P$ is a probability measure on $\mathcal{F}$ such that $P(\Omega) = 1$
    \end{enumerate}
\end{definition}

\begin{definition}[Joint Probability]
    The joint probability of two events $A$ and $B$ is:
    \begin{equation*}
        P(A, B) := P(A \cap B) 
    \end{equation*}
\end{definition}

\begin{definition}[Random Variable]
    A random variable $X$ is a function $X: \Omega \rightarrow \mathbb{R}$. 

    Val(X) = Image(X) = $\{ x \in \mathbb{R} : \exists \omega \in \Omega \text{ s.t. } X(\omega) = x \}$
\end{definition}

\begin{definition}[Probability Mass Function (PMF)]
    The probability mass function of a random variable $X$ is:
    \begin{equation*}
        P(X = x) := P(\{ \omega \in \Omega : X(\omega) = x \})
    \end{equation*}
\end{definition}

\begin{definition}[Joint Distribution]
    A joint distribution over a set of RVs $\mathcal{X} = \{ X_1, X_2, \ldots, X_n \}$ is a probability distribution 
    $P_{\mathcal{X}}: Val(X_1) \times Val(X_2) \times \ldots \times Val(X_n) \rightarrow [0, 1]$ defined by:
    \begin{equation*}
       \forall x_1, \ldots, x_n : x_i \in Val(X_i) \quad
        P_{\mathcal{X}}(x_1, x_2, \ldots, x_n) := P(X_1 = x_1, X_2 = x_2, \ldots, X_n = x_n)
    \end{equation*}
\end{definition}

\begin{theorem}[Law of Total Probability]
    For X, Y random variables, we can write:
    \begin{equation*}
        P(X) = \sum_{y \in Val(Y)} P(X, Y = y) 
    \end{equation*}
\end{theorem}












% * * * * * * * * * * * * * * * * * * * * * * * * 
% * * * * * * * * * * * * * * * * * * * * * * * * 
% * * * * * * * * * * * * * * * * * * * * * * * * 
% * * * * * * * * * * * * * * * * * * * * * * * * 
% * * * * * * * * * * * * * * * * * * * * * * * * 
% * * * * * * * * * * * * * * * * * * * * * * * * 
% * * * * * * * * * * * * * * * * * * * * * * * * 
% * * * * * * * * * * * * * * * * * * * * * * * * 
% * * * * * * * * * * * * * * * * * * * * * * * * 
% * * * * * * * * * * * * * * * * * * * * * * * * 
% * * * * * * * * * * * * * * * * * * * * * * * * 
% * * * * * * * * * * * * * * * * * * * * * * * * 
% * * * * * * * * * * * * * * * * * * * * * * * * 
% * * * * * * * * * * * * * * * * * * * * * * * * 
% * * * * * * * * * * * * * * * * * * * * * * * * 
% * * * * * * * * * * * * * * * * * * * * * * * * 
% * * * * * * * * * * * * * * * * * * * * * * * * 
% * * * * * * * * * * * * * * * * * * * * * * * * 
% * * * * * * * * * * * * * * * * * * * * * * * * 
\newpage
\section{Bayesian Networks}

\begin{theorem}[Chain Rule]
    For any set of random variables $X_1, X_2, \ldots, X_n$:
    \begin{equation*}
        P(X_1, X_2, \ldots, X_n) = P(X_1)P(X_2 | X_1)P(X_3 | X_1, X_2) \ldots P(X_n | X_1, X_2, \ldots, X_{n-1})
    \end{equation*}
\end{theorem}

\begin{definition}[Conditional probability distribution]
    The conditional probability distribution of a random variable $X$ given another random variable $Y$ is:
    \begin{equation*}
        P(X_i | Y) = \frac{P(X_i, Y)}{P(Y)} = \frac{P(X_i, Y)}{\sum_{i} P(X_i, Y)}
    \end{equation*}
\end{definition}

\begin{definition}[Bayesian Network]
    A Bayesian Network $B$ is:
    \begin{enumerate}
        \item A directed acyclic graph (DAG) $G = (V, E)$
        \item A set of conditional probability distributions $P_i(X_i | \text{Pa}(X_i))$ for each node $X_i$ in the graph
    \end{enumerate}
    the network defines a probability distribution: 
    \begin{equation*}
        P_B(X_1, X_2, \ldots, X_n) = \prod_{i=1}^{n} P_i(X_i | \text{Pa}(X_i))
    \end{equation*}
\end{definition}

\begin{theorem}[Bayesian Network defines a probability distribution]
    For any Bayesian Network $B$, $P_B(X_1, X_2, \ldots, X_n)$ is a joint probability distribution over the variables $X_1, X_2, \ldots, X_n$.
\end{theorem}

\begin{definition}[$I_{LM}(G)$]
    The \textbf{Local Markov Independencies Set} of a Bayesian Network $B$ is the set of all independencies that hold in the network:
    \begin{equation*}
        I_{LM}(G) = \{ (X_i \perp ND(X_i) | \text{Pa}(X_i)) \quad : i \in |V| \}
    \end{equation*}
\end{definition}

\begin{definition}[I-map]
    A DAG $G$ is an I-map of a distribution $P$ if all independencies assumptions of $G$ hold in $P$:
    \begin{equation*}
        I_{LM}(G) \subseteq I(P)
    \end{equation*}
\end{definition}

\begin{theorem}[If $G$ is an I-map of $P$, then $P$ factorizes according to $G$]
    If $G$ is an I-map of $P$, then
    \begin{equation*}
        P(X_1, X_2, \ldots, X_n) = \prod_{i=1}^{n} P(X_i | \text{Pa}(X_i))
    \end{equation*}
\end{theorem}

\begin{theorem}[Independencies in $P_B$]
    For $P_B$ it holds for all $i$ that
    \begin{enumerate}
        \item $X_i \perp ND(X_i) | \text{Pa}(X_i)$  \quad  ($I_{LM}(G)$)
        \item $P_B(X_i | ND(X_i)) = P_i(X_i | \text{Pa}(X_i))$
    \end{enumerate}
\end{theorem}

\begin{definition}[Minimal I-map]
    A DAG $G$ is a minimal I-map of a distribution $P$ if 
    \begin{enumerate}
        \item $G$ is an I-map of $P$
        \item If $G' \subset G$ then $G'$ is not an I-map of $P$
    \end{enumerate}
\end{definition}


\end{document}